{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# This is done so that the notebook can see files\n",
    "# placed in a different folder\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from environment.Environment import Env2048\n",
    "\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(Env2048())\n",
    "eval_env = tf_py_environment.TFPyEnvironment(Env2048())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected q_network to emit a floating point tensor with inner dims (4,); but saw network output spec: TensorSpec(shape=(4, 4), dtype=tf.float32, name=None)\n  In call to configurable 'DqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DqnAgent'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ef8f1b029268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_step_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m agent = dqn_agent.DqnAgent(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtime_step_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maction_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/agents/dqn/dqn_agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, time_step_spec, action_spec, q_network, optimizer, observation_and_action_constraint_splitter, epsilon_greedy, n_step_update, boltzmann_temperature, emit_log_probability, target_q_network, target_update_tau, target_update_period, td_errors_loss_fn, gamma, reward_scale_factor, gradient_clipping, debug_summaries, summarize_grads_and_vars, train_step_counter, training_data_spec, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m         name='TargetQNetwork')\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_network_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q_network'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_network_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_q_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_q_network'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/agents/dqn/dqn_agent.py\u001b[0m in \u001b[0;36m_check_network_output\u001b[0;34m(self, net, label)\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmismatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m     network_utils.check_single_floating_network_output(\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mexpected_output_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/networks/utils.py\u001b[0m in \u001b[0;36mcheck_single_floating_network_output\u001b[0;34m(output_spec, expected_output_shape, label)\u001b[0m\n\u001b[1;32m     36\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0moutput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_output_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m           and output_spec.dtype.is_floating):\n\u001b[0;32m---> 38\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;34m'Expected {} to emit a floating point tensor with inner dims '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m'{}; but saw network output spec: {}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected q_network to emit a floating point tensor with inner dims (4,); but saw network output spec: TensorSpec(shape=(4, 4), dtype=tf.float32, name=None)\n  In call to configurable 'DqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DqnAgent'>)"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    time_step_spec = train_env.time_step_spec(),\n",
    "    action_spec = train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n"
     ]
    }
   ],
   "source": [
    "env = tf_py_environment.TFPyEnvironment(Env2048())\n",
    "# env = Env2048()\n",
    "\n",
    "rewards = []\n",
    "max_rewards = []\n",
    "steps = []\n",
    "total_rewards = []\n",
    "env.reset()\n",
    "\n",
    "for i in range(3000):\n",
    "    if not i % 100:\n",
    "        print(i)\n",
    "    time_step = env.step(np.array(np.random.randint(4), dtype=np.int32))\n",
    "    while not time_step.is_last():\n",
    "        time_step = env.step(np.array(np.random.randint(4), dtype=np.int32))\n",
    "    if time_step.is_last():\n",
    "        pyenv = env.pyenv.envs[0]\n",
    "#         pyenv = env\n",
    "        rewards += pyenv.get_state().reward_history\n",
    "        steps += [pyenv.get_state().step_count]\n",
    "        total_rewards += [pyenv.get_state().total_reward]\n",
    "        max_rewards += [pyenv.get_state().max_reward]\n",
    "        env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12.,  96., 132.,  11., 495., 349., 232.,  41.,  35.,   2., 364.,\n",
       "        501., 323.,  84.,  82.,  18.,   4.,   6.,   5.,   1.,   0.,   0.,\n",
       "          0.,  56.,  70.,  43.,  17.,  13.,   2.,   2.,   3.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([ 20.  ,  29.92,  39.84,  49.76,  59.68,  69.6 ,  79.52,  89.44,\n",
       "         99.36, 109.28, 119.2 , 129.12, 139.04, 148.96, 158.88, 168.8 ,\n",
       "        178.72, 188.64, 198.56, 208.48, 218.4 , 228.32, 238.24, 248.16,\n",
       "        258.08, 268.  , 277.92, 287.84, 297.76, 307.68, 317.6 , 327.52,\n",
       "        337.44, 347.36, 357.28, 367.2 , 377.12, 387.04, 396.96, 406.88,\n",
       "        416.8 , 426.72, 436.64, 446.56, 456.48, 466.4 , 476.32, 486.24,\n",
       "        496.16, 506.08, 516.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.hist(rewards, bins=50)\n",
    "# plt.hist(steps, bins=50)\n",
    "# plt.hist(total_rewards, bins=50)\n",
    "plt.hist(max_rewards, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_8",
   "language": "python",
   "name": "python3_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
